	For Part 3, I went with Option A, the data cleaning challenge. Basically, I cleaned up the scraped data by stripping out the '£' symbols and converting prices to actual numbers so I could do calculations with them. Same thing with the star ratings, I converted the word versions (like "Three" or "Five") to numbers (3, 5, etc.). I also added a HighlyRated column that flags books with 4 or 5 stars as "Yes" and everything else as "No." 
	I ran into a couple of annoying issues along the way. The star rating thing was frustrating at first because my code wasn't finding any ratings. Turns out I used the wrong HTML tag. Once I switched to find_all("p", class_="star-rating"), it worked fine. The other problem was by far the most annoying. When I opened my CSV in Excel, the "£" symbol showed up as "Â£" instead. Turns out it was a file encoding issue, and I fixed it by saving the file with UTF-8 encoding. 
	Overall, this project was useful for getting the hang of web scraping. I learned how to use Requests and BeautifulSoup to pull data from websites and find what I needed using HTML tags and classes. The Pandas stuff was helpful too for organizing data, cleaning it up, and exporting it to CSV. Definitely feel more comfortable with data cleaning and working with files in Python now.